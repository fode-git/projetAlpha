{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "df = pd.read_csv('A_Z Handwritten Data/A_Z Handwritten Data.csv', header=None)\n",
    "\n",
    "# Extraire labels et images\n",
    "labels = df.iloc[:, 0].values\n",
    "images = df.iloc[:, 1:].values\n",
    "\n",
    "# Normaliser et reshape en (N, 1, 28, 28) pour PyTorch (1 channel)\n",
    "images = images.astype('float32') / 255.0\n",
    "images = images.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AZDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = torch.tensor(images)\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test (exemple 80/20)\n",
    "train_imgs, test_imgs, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_data = AZDataset(train_imgs, train_labels)\n",
    "test_data = AZDataset(test_imgs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir le model\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 26)  # 26 classes A-Z\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)  # 2x2 kernel and stride 2\n",
    "        # second pass\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16*5*5)  # Flatten\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration du device, loss et optimiseur\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modele = ConvolutionalNetwork().to(device)\n",
    "critere = nn.NLLLoss()\n",
    "optimiseur = torch.optim.Adam(modele.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 600 | Loss: 0.3516\n",
      "Epoch: 1 | Batch: 1200 | Loss: 0.2336\n",
      "Epoch: 1 | Batch: 1800 | Loss: 0.0545\n",
      "Epoch: 1 | Batch: 2400 | Loss: 0.3655\n",
      "Epoch: 1 | Batch: 3000 | Loss: 0.0729\n",
      "Epoch: 1 | Batch: 3600 | Loss: 0.1189\n",
      "Epoch: 1 | Batch: 4200 | Loss: 0.3070\n",
      "\n",
      ">>> Époque 1/5\n",
      "Train Loss: 0.2584 | Train Accuracy: 92.52%\n",
      "Test  Loss: 0.1053 | Test  Accuracy: 96.92%\n",
      "--------------------------------------------------\n",
      "Epoch: 2 | Batch: 600 | Loss: 0.0494\n",
      "Epoch: 2 | Batch: 1200 | Loss: 0.0513\n",
      "Epoch: 2 | Batch: 1800 | Loss: 0.0315\n",
      "Epoch: 2 | Batch: 2400 | Loss: 0.0256\n",
      "Epoch: 2 | Batch: 3000 | Loss: 0.1108\n",
      "Epoch: 2 | Batch: 3600 | Loss: 0.1062\n",
      "Epoch: 2 | Batch: 4200 | Loss: 0.1499\n",
      "\n",
      ">>> Époque 2/5\n",
      "Train Loss: 0.0868 | Train Accuracy: 97.47%\n",
      "Test  Loss: 0.0690 | Test  Accuracy: 98.03%\n",
      "--------------------------------------------------\n",
      "Epoch: 3 | Batch: 600 | Loss: 0.0385\n",
      "Epoch: 3 | Batch: 1200 | Loss: 0.1001\n",
      "Epoch: 3 | Batch: 1800 | Loss: 0.0478\n",
      "Epoch: 3 | Batch: 2400 | Loss: 0.0399\n",
      "Epoch: 3 | Batch: 3000 | Loss: 0.0586\n",
      "Epoch: 3 | Batch: 3600 | Loss: 0.1192\n",
      "Epoch: 3 | Batch: 4200 | Loss: 0.0222\n",
      "\n",
      ">>> Époque 3/5\n",
      "Train Loss: 0.0644 | Train Accuracy: 98.13%\n",
      "Test  Loss: 0.0586 | Test  Accuracy: 98.33%\n",
      "--------------------------------------------------\n",
      "Epoch: 4 | Batch: 600 | Loss: 0.1800\n",
      "Epoch: 4 | Batch: 1200 | Loss: 0.1081\n",
      "Epoch: 4 | Batch: 1800 | Loss: 0.0443\n",
      "Epoch: 4 | Batch: 2400 | Loss: 0.0317\n",
      "Epoch: 4 | Batch: 3000 | Loss: 0.0737\n",
      "Epoch: 4 | Batch: 3600 | Loss: 0.1273\n",
      "Epoch: 4 | Batch: 4200 | Loss: 0.0085\n",
      "\n",
      ">>> Époque 4/5\n",
      "Train Loss: 0.0523 | Train Accuracy: 98.45%\n",
      "Test  Loss: 0.0568 | Test  Accuracy: 98.37%\n",
      "--------------------------------------------------\n",
      "Epoch: 5 | Batch: 600 | Loss: 0.0660\n",
      "Epoch: 5 | Batch: 1200 | Loss: 0.0707\n",
      "Epoch: 5 | Batch: 1800 | Loss: 0.0176\n",
      "Epoch: 5 | Batch: 2400 | Loss: 0.0185\n",
      "Epoch: 5 | Batch: 3000 | Loss: 0.0316\n",
      "Epoch: 5 | Batch: 3600 | Loss: 0.0378\n",
      "Epoch: 5 | Batch: 4200 | Loss: 0.0177\n",
      "\n",
      ">>> Époque 5/5\n",
      "Train Loss: 0.0443 | Train Accuracy: 98.67%\n",
      "Test  Loss: 0.0468 | Test  Accuracy: 98.65%\n",
      "--------------------------------------------------\n",
      "\n",
      "Entraînement terminé en 38.63 minutes\n"
     ]
    }
   ],
   "source": [
    "# Démarrer un chronomètre pour mesurer le temps total d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "# Listes pour suivre les pertes et les bonnes prédictions\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "# Boucle sur les époques\n",
    "for epoch in range(epochs):\n",
    "    modele.train()\n",
    "    trn_corr = 0\n",
    "    total_loss = 0\n",
    " # Boucle sur les batches d'entraînement\n",
    "    for b, (X_train, y_train) in enumerate(train_loader, start=1):\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        #Forward pass : faire une prédiction\n",
    "        y_pred = modele(X_train)\n",
    "        loss = critere(y_pred, y_train)\n",
    "        # Calculer le nombre de bonnes prédictions sur ce batch\n",
    "        predicted = torch.argmax(y_pred.data, dim=1)\n",
    "        batch_corr = (predicted == y_train).sum().item()\n",
    "        trn_corr += batch_corr\n",
    "        # Backpropagation et mise à jour des poids\n",
    "        optimiseur.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiseur.step()\n",
    "        # Ajouter la perte de ce batch à la perte totale\n",
    "        total_loss += loss.item()\n",
    "        # Afficher un état toutes les 600 itérations\n",
    "        if b % 600 == 0:\n",
    "            print(f\"Epoch: {epoch+1} | Batch: {b} | Loss: {loss.item():.4f}\")\n",
    "    # Moyenne de la perte pour l'époque complète\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    train_correct.append(trn_corr)\n",
    "#---------------Phase de test------------------\n",
    "    modele.eval()\n",
    "    tst_corr = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                        # Prédiction\n",
    "            y_val = modele(X_test)\n",
    "               # Calcul de la perte\n",
    "            loss = critere(y_val, y_test)\n",
    "            total_test_loss += loss.item()\n",
    "  # Nombre de bonnes prédictions\n",
    "            predicted = torch.argmax(y_val, dim=1)\n",
    "            tst_corr += (predicted == y_test).sum().item()\n",
    "  # Moyenne de la perte en test\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_correct.append(tst_corr)\n",
    "    # Résumé de l'époque\n",
    "    print(f\"\\n>>> Époque {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {avg_loss:.4f} | Train Accuracy: {trn_corr / len(train_data) * 100:.2f}%\")\n",
    "    print(f\"Test  Loss: {avg_test_loss:.4f} | Test  Accuracy: {tst_corr / len(test_data) * 100:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "# Temps total d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"\\nEntraînement terminé en {((end_time - start_time) / 60):.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tester une image individuelle et affichage\n",
    "idx = 4743\n",
    "image, label = test_data[idx]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label réel: {chr(label + ord('A'))}\")\n",
    "plt.show()\n",
    "\n",
    "modele.eval()\n",
    "with torch.no_grad():\n",
    "    input_img = image.unsqueeze(0).to(device)  # batch size = 1\n",
    "    output = modele(input_img)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "\n",
    "print(f\"Prédiction du modèle : {chr(pred_class + ord('A'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #code avoir si non appliquer à supprimer \n",
    "device = torch.device(\"cpu\")\n",
    "model_path = \"mon_modele.pth\"\n",
    "\n",
    "if os.path.exists(model_path) and os.path.getsize(model_path) > 0:\n",
    "    modele.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    modele.eval()\n",
    "    print(f\"✅ Modèle chargé depuis {model_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Fichier {model_path} introuvable ou vide. Entraîne le modèle avant de charger.\")\n",
    "\n",
    "print(\"Répertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #code avoir si non appliquer à supprimer \n",
    "\n",
    " # Sauvegarder modèle entraîné\n",
    "torch.save(modele.state_dict(), model_path)\n",
    "print(f\"✅ Modèle entraîné et sauvegardé dans {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
